{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNS9iahQbQEqU4u67CIZgt8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Practical 5 : Implement Artificial Neural Network training process in Python by using Forward Propagation, Back Propagation"],"metadata":{"id":"0jX9XUJCG_Pw"}},{"cell_type":"markdown","source":["Method 1"],"metadata":{"id":"LzUf0ME7LlfU"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nCBSz8o4Gn3S","executionInfo":{"status":"ok","timestamp":1745739251728,"user_tz":-330,"elapsed":933,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}},"outputId":"3fbf5be7-cb3d-488b-b89f-11d13d6ce048"},"outputs":[{"output_type":"stream","name":"stdout","text":["[0.9897704]\n"]}],"source":["from joblib.numpy_pickle_utils import xrange\n","from numpy import *\n","\n","class NeuralNet(object):\n","  def __init__(self):\n","    # Generate random numbers\n","    random.seed(1)\n","    # Assign random weights to a 3 x 1 matrix,\n","    self.synaptic_weights = 2 * random.random((3, 1)) - 1\n","\n","  # The Sigmoid function\n","  def __sigmoid(self, x):\n","    return 1 / (1 + exp(-x))\n","    # The derivative of the Sigmoid function.\n","\n","  # This is the gradient of the Sigmoid curve.\n","  def __sigmoid_derivative(self, x):\n","    return x * (1 - x)\n","\n","  # Train the neural network and adjust the weights each time.\n","  def train(self, inputs, outputs, training_iterations):\n","    for iteration in xrange(training_iterations):\n","    # Pass the training set through the network.\n","      output = self.learn(inputs)\n","      # Calculate the error\n","      error = outputs - output\n","      # Adjust the weights by a factor\n","      factor = dot(inputs.T, error * self.__sigmoid_derivative(output))\n","      self.synaptic_weights += factor\n","\n","  # The neural network thinks.\n","  def learn(self, inputs):\n","    return self.__sigmoid(dot(inputs, self.synaptic_weights))\n","\n","if __name__ == \"__main__\":\n","  # Initialize\n","  neural_network = NeuralNet()\n","  # The training set.\n","  inputs = array([[0, 1, 1], [1, 0, 0], [1, 0, 1]])\n","  outputs = array([[1, 0, 1]]).T\n","  # Train the neural network\n","  neural_network.train(inputs, outputs, 10000)\n","  # Test the neural network with a test example.\n","  print(neural_network.learn(array([1, 0, 1])))"]},{"cell_type":"markdown","source":["Method 2"],"metadata":{"id":"o6ezwZZjLoCk"}},{"cell_type":"code","source":["import numpy as np\n","# Define the sigmoid activation function and its derivative\n","def sigmoid(x):\n","  return 1 / (1 + np.exp(-x))\n","def sigmoid_derivative(x):\n","  return x * (1 - x)\n","# Define the input and target output data\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([[0], [1], [1], [0]])\n","# Define the neural network structure and initialize weights\n","input_size = 2\n","hidden_size = 2\n","output_size = 1\n","weights_input_hidden = np.random.uniform(size=(input_size, hidden_size))\n","weights_hidden_output = np.random.uniform(size=(hidden_size, output_size))\n","# Set the learning rate and number of epochs\n","learning_rate = 0.1\n","num_epochs = 10000\n","# Define the training loop\n","for i in range(num_epochs):\n","# Forward propagation\n","  hidden_layer_input = np.dot(X, weights_input_hidden)\n","  hidden_layer_activation = sigmoid(hidden_layer_input)\n","  output_layer_input = np.dot(hidden_layer_activation, weights_hidden_output)\n","  output_layer_activation = sigmoid(output_layer_input)\n","# Calculate the error and delta for backpropagation\n","  error = y - output_layer_activation\n","  output_delta = error * sigmoid_derivative(output_layer_activation)\n","  hidden_delta = output_delta.dot(weights_hidden_output.T) * sigmoid_derivative(hidden_layer_activation)\n","# Update the weights\n","  weights_hidden_output += hidden_layer_activation.T.dot(output_delta) * learning_rate\n","  weights_input_hidden += X.T.dot(hidden_delta) * learning_rate\n","# Make predictions on the input data\n","hidden_layer_input = np.dot(X, weights_input_hidden)\n","hidden_layer_activation = sigmoid(hidden_layer_input)\n","output_layer_input = np.dot(hidden_layer_activation, weights_hidden_output)\n","output_layer_activation = sigmoid(output_layer_input)\n","print(output_layer_activation)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C1RXjBG4KtpS","executionInfo":{"status":"ok","timestamp":1745739393951,"user_tz":-330,"elapsed":643,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}},"outputId":"c7dd7c23-68c0-4763-bf92-b87c3e6f7358"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0.50010285]\n"," [0.50034169]\n"," [0.49986788]\n"," [0.50010505]]\n"]}]},{"cell_type":"markdown","source":["Method 3"],"metadata":{"id":"VUNccgAnLq4Q"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Activation function (sigmoid)\n","def sigmoid(x):\n","    return 1 / (1 + np.exp(-x))\n","\n","# Derivative of sigmoid function\n","def sigmoid_derivative(x):\n","    return x * (1 - x)"],"metadata":{"id":"G1x6hxLvLSg3","executionInfo":{"status":"ok","timestamp":1745739507759,"user_tz":-330,"elapsed":7,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# Define the ANN class\n","class NeuralNetwork:\n","    def __init__(self, layers):\n","        self.layers = layers\n","        self.weights = []\n","        for i in range(1, len(layers)):\n","            self.weights.append(np.random.randn(layers[i - 1], layers[i]))\n","\n","    def forward_propagation(self, X):\n","        self.activations = [X]\n","        self.z_values = []\n","        for i in range(len(self.layers) - 1):\n","            z = np.dot(self.activations[i], self.weights[i])\n","            self.z_values.append(z)\n","            activation = sigmoid(z)\n","            self.activations.append(activation)\n","        return self.activations[-1]\n","\n","    def backward_propagation(self, X, y, learning_rate):\n","        output = self.forward_propagation(X)\n","        error = y - output\n","        delta = error * sigmoid_derivative(output)\n","\n","        for i in range(len(self.layers) - 2, -1, -1):\n","            gradient = np.dot(self.activations[i].T, delta)\n","            self.weights[i] += learning_rate * gradient\n","\n","            error = np.dot(delta, self.weights[i].T)\n","            delta = error * sigmoid_derivative(self.activations[i])\n","\n","    def train(self, X, y, epochs, learning_rate):\n","        for epoch in range(epochs):\n","            self.backward_propagation(X, y, learning_rate)\n","\n","        return self.forward_propagation(X)"],"metadata":{"id":"ffjjCLO1LudK","executionInfo":{"status":"ok","timestamp":1745739566015,"user_tz":-330,"elapsed":7,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Testing the ANN\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([[0], [1], [1], [0]])\n","\n","# Define the network architecture\n","layers = [2, 4, 1]\n","\n","# Create an instance of the NeuralNetwork class\n","nn = NeuralNetwork(layers)\n","\n","# Train the network\n","output = nn.train(X, y, epochs=10000, learning_rate=0.1)"],"metadata":{"id":"f52cagMcL8rw","executionInfo":{"status":"ok","timestamp":1745739578028,"user_tz":-330,"elapsed":683,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["# Print the output after training\n","print(\"Output after training:\")\n","print(output)"],"metadata":{"id":"Agnv4ZbnL_bZ","executionInfo":{"status":"ok","timestamp":1745739588334,"user_tz":-330,"elapsed":92,"user":{"displayName":"Abizer Lunawadawala","userId":"10706016738865616886"}},"outputId":"19ad2408-4351-46f3-d6a3-fc4bb36db4be","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Output after training:\n","[[0.07019614]\n"," [0.94126975]\n"," [0.93136228]\n"," [0.06801957]]\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"pymXOLRoMCHU"},"execution_count":null,"outputs":[]}]}